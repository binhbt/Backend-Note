Parameters in general are weights that are learnt during training.  
Input layer: parameters = 0  
Convolution layer: params = ((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)  
POOL layer: parameters = 0 
Fully Connected Layer (FC): params = ((current layer neurons c * previous layer neurons p)+1*c).  

batch size: The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.
(Mini-Batch Gradient Descent. 1 < Batch Size < Size of Training Set)  
steps_per_epoch = Size of Training Set/batch size  
Epoch: The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.
(for i in (0..epochs)){gradient_decent_function}  




